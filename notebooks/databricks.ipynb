{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('env')",
   "metadata": {
    "interpreter": {
     "hash": "18b08cc3eecd310d4db0199bee5cd64e02dad618a064d16edca19ec84c59e158"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import desc\n",
    "from pyspark.sql.functions import asc\n",
    "from pyspark.sql.functions import sum as Fsum\n",
    "from pyspark.sql.functions import avg as Favg\n",
    "from pyspark.sql.functions import count as Fcount\n",
    "from pyspark.sql.functions import countDistinct as FcountDistinct\n",
    "from pyspark.sql.functions import min as Fmin\n",
    "from pyspark.sql.functions import max as Fmax\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import MinMaxScaler, VectorAssembler, StringIndexer\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n"
   ]
  },
  {
   "source": [
    "# Load Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpath = '../data/sparkify_event_data.j'\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName('sparkify_etl')\\\n",
    "        .getOrCreate()\n",
    "\n",
    "df = spark.read.json(dfpath)\n"
   ]
  },
  {
   "source": [
    "# Clean data\n",
    "\n",
    "As there is no value in looking at users that are not logged in for churn analysis - their entries will be disregarded. \n",
    "The empty `Artist`, `Song` and `Length` values will not be removed, as the rest of their rows may provide valuable data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns that are unlikely to be valuable\n",
    "valuable_columns = ['artist', 'auth', 'gender', 'itemInSession', 'level', 'location', 'page', 'registration', 'sessionId', 'song', 'status', 'ts', 'userAgent', 'userId']\n",
    "df = df.select(valuable_columns)\n",
    "\n",
    "df = df.filter(df.auth.isin(['Logged Out', 'Guest']) == False)"
   ]
  },
  {
   "source": [
    "# Feature Engineering"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "def detect_os(column):\n",
    "    '''\n",
    "        summary:\n",
    "            Transformes the userId userAgent column into the platform used by the user\n",
    "            * Microsoft\n",
    "            * Apple\n",
    "            * Linux\n",
    "        args:\n",
    "            column - column to be transformed\n",
    "        returns:\n",
    "            Name of the platform used\n",
    "    '''\n",
    "    detect = re.findall(r'\\((\\w+)', column)[0]\n",
    "    if detect in ['iPhone', 'iPad', 'Macintosh']:\n",
    "        return 'Apple'\n",
    "    elif detect in ['Windows', 'compatible']:\n",
    "        return'Microsoft'\n",
    "    elif detect in ['X11']:\n",
    "        return'Linux'\n",
    "    else:\n",
    "        return 'Not Detected'\n",
    "\n",
    "detect_os_udf = udf(detect_os)\n",
    "\n",
    "# Create platform and age in hours column\n",
    "df = df.withColumn('platform', detect_os_udf(df.userAgent))\\\n",
    "        .withColumn('ageHours', (df.ts - df.registration)/3600000)\\\n",
    "        .drop('userAgent')\n",
    "\n",
    "df = df.withColumn('levelNr', when(\n",
    "    col('level') == 'paid', 1)\n",
    "    .otherwise(0)\n",
    ")"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "## Define and flag churn\n",
    "\n",
    "Churn defined as having a `Cancellation Confirmation` page visit"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flag_cancellation_event = udf(lambda x: 1 if x == \"Cancellation Confirmation\" else 0, IntegerType())\n",
    "df_churn = df.withColumn('ChurnFlag', flag_cancellation_event('page'))\n",
    "windowed = Window.partitionBy('userId').orderBy(desc('ts')).rangeBetween(Window.unboundedPreceding, 0)\n",
    "df_churn = df_churn.withColumn('Churned', Fsum('ChurnFlag').over(windowed))\n",
    "df_churn.filter(df_churn.Churned == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag the last month of user data per user\n",
    "\n",
    "user_level = df_churn.groupBy('userId')\\\n",
    "                .agg(\n",
    "                    Fmax('ts').alias('latestSession'), \n",
    "                    Fmax(when(col('ChurnFlag') == 1, col('ts'))).alias('ChurnTime'))\n",
    "df_churn = df_churn.join(user_level, on= 'userId', how='left')\n",
    "df_churn = df_churn.withColumn(\n",
    "    'lastMonth',\n",
    "        when(col('churned') == 1, (col('ChurnTime') - col('ts')) /3600000 <= 720)\n",
    "        .otherwise((col('latestSession') - col('ts')) /3600000 <= 720))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate on user level\n",
    "\n",
    "df_last_month = df_churn\\\n",
    "    .filter(col('lastMonth') == True)\\\n",
    "    .groupBy(['userId', 'platform', 'Churned'])\\\n",
    "    .agg(\n",
    "        Fmax(col('levelNr')).alias('premiumUser'),\n",
    "        Fmax(col('ageHours')).alias('ageHours'),\n",
    "        Fsum(when(col('page') == 'NextSong', 1)).alias('songsListened'),\n",
    "        Fsum(when(col('page') == 'Thumbs Down', 1)).alias('downVotes'),    \n",
    "    )\n",
    "\n",
    "df_last_month= df_last_month.fillna({\n",
    "    'downVotes':0,\n",
    "    'songsListened':0\n",
    "})\n",
    "\n",
    "df_last_month.show()"
   ]
  },
  {
   "source": [
    "## EDA & Feature Engineering results\n",
    "\n",
    "Taken from the EDA on the smaller data subset.\n",
    "\n",
    "|         | Not Churned | Churned |\n",
    "|---------|-------------|---------|\n",
    "| female  | 44%         | 45%     |\n",
    "| apple   | 44%         | 46,5%   |\n",
    "| Windows | 49.9%       | 48.5%   |\n",
    "| Linux   | 6.1%        | 5%      |\n",
    "\n",
    "* It does not look like gender has an influence on churn.\n",
    "* apple users are slightly more likely to churn compared to Linux and Windows users.\n",
    "* Churned users seem to be slightly more engaged, having a higher percentage of premium users, more items per session, songs listened and votes in general. \n",
    "* The one thing that stands out is that they have way give way more Down Votes on average. \n",
    "* They seem to be relatively newer to the service than the non churned users."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Select and transform valuable features\n",
    "\n",
    "* Platform\n",
    "* Level\n",
    "* User Age\n",
    "* Songs listened\n",
    "* Down Votes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['label', 'platformIndexed', 'premiumUser', 'ageHours', 'songsListened', 'downVotes']\n",
    "\n",
    "indexer = StringIndexer(inputCol='platform', outputCol='platformIndexed')\n",
    "df_user = indexer.fit(df_last_month)\\\n",
    "            .transform(df_last_month)\\\n",
    "            .withColumnRenamed('Churned', 'label')\\\n",
    "            .select(features)\n",
    "\n",
    "df_user.show()"
   ]
  },
  {
   "source": [
    "# Modeling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df_user.randomSplit([0.8, 0.2], 23)\n",
    "\n",
    "feature_names = ['platformIndexed', 'premiumUser', 'ageHours', 'songsListened', 'downVotes']\n",
    "assembler = VectorAssembler(inputCols = feature_names, outputCol = 'features_vectorized')\n",
    "scaler = MinMaxScaler(inputCol = 'features_vectorized', outputCol = 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(model, param_grid, data):\n",
    "    '''\n",
    "        summary:\n",
    "            Runs the pipeline for the provided model based on the provided parameter grid.\n",
    "        args:\n",
    "            model - model to be trained\n",
    "            param_grid - parameter grid that is to be evaluated\n",
    "            data - training data set to use\n",
    "        returns:\n",
    "            trained_model - the trained model\n",
    "    '''\n",
    "    pipeline = Pipeline(stages = [assembler, scaler, model])\n",
    "    crossval = CrossValidator(\n",
    "        estimator=pipeline,\n",
    "        estimatorParamMaps=param_grid,\n",
    "        evaluator=MulticlassClassificationEvaluator(metricName='f1'),\n",
    "        numFolds=3)\n",
    "    trained_model = crossval.fit(data)\n",
    "    return trained_model\n",
    "\n",
    "def evaluate_model(model, data):\n",
    "    '''\n",
    "        summary:\n",
    "            Evaluates the performance of a model using the f1-score.\n",
    "            f1-score is chosen as it provides a good balance between\n",
    "            recall and precision.\n",
    "        args:\n",
    "            model - model to be evaluated\n",
    "            data - test data set to use\n",
    "        returns:\n",
    "            score - f1-score of the model\n",
    "            confustion_matrix - confusion matrix of the model\n",
    "    '''\n",
    "    evaluator = MulticlassClassificationEvaluator(metricName= 'f1')\n",
    "    predictions = model.transform(data)\n",
    "\n",
    "    score = evaluator.evaluate(predictions)\n",
    "    confusion_matrix = predictions.groupby('label')\\\n",
    "                        .pivot('prediction')\\\n",
    "                        .count()\\\n",
    "                        .toPandas()\n",
    "    return score, confusion_matrix"
   ]
  },
  {
   "source": [
    "## Multilayer Perceptron"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = MultilayerPerceptronClassifier()\n",
    "\n",
    "param_grid = ParamGridBuilder()\\\n",
    "                .addGrid(mp.layers, [[5, 4, 2]])\\\n",
    "                .addGrid(mp.blockSize, [32])\\\n",
    "                .build()\n",
    "\n",
    "mp_model = run_pipeline(mp, param_grid, train)\n",
    "\n",
    "mp_score, mp_confusion = evaluate_model(mp_model, test)\n",
    "print(f'The score for the multiplayer perceptron is {mp_score:.4f}')\n",
    "print(mp_confusion)"
   ]
  },
  {
   "source": [
    "# Closing words\n",
    "\n",
    "The multilayer perceptron seems to be performing the best on the small dataset with an f1-score of 0.795 and a favorable confusion matrix. \n",
    "The configuration used to achieve these results are :\n",
    "* 5 nodes in the input layer\n",
    "* 4 nodes in the first intermediate layer\n",
    "* 2 nodes in the output layer\n",
    "* A block size of 32\n",
    "\n",
    "How does this hold up against the full data set?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}